spark_machine=$(docker ps | grep 'spark-cli' | grep -o '[^ ]*spark-solo[^ ]*')
process_jar=NewYorker-assembly-1.0.jar

docker exec -it $spark_machine mkdir datafiles
docker exec -it $spark_machine mkdir datafiles_t


#small file (head from main)
docker cp small_dataset.tar.gz $spark_machine:/datafiles_t

#full file
docker cp yelp_dataset.tar $spark_machine:/datafiles

cassandra_machine=$(docker ps | grep 'cassandra' | grep -o '[^ ]*cassandra[^ ]*'|tail -1)

#Send jar
docker cp $process_jar $spark_machine:/

#Base Sanity Test
docker exec -it $spark_machine spark-submit --class pcontop.ny.lab.reader.TestRun /$process_jar

#Run Small
docker exec -it $spark_machine spark-submit --class pcontop.ny.lab.reader.Reader /$process_jar /datafiles_t $cassandra_machine

#Run Big
docker exec -it \
$spark_machine spark-submit \
--class pcontop.ny.lab.reader.Reader \
--executor-memory 3g \
--num-executors 2 \
/$process_jar /datafiles $cassandra_machine



